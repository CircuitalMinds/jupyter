{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Solving systems of linear equations and related topics in numerical linear algebra are essential to an enormous range of engineering applications. Whether it's process control, large scale optimization, process design or simulation, understanding the formulation and solution of linear systems is an essential skill for modern engineering practice.\n",
    "\n",
    "In a nutshell, the challenge is to compute a numerical solution to a system of $m$ linear equations in $n$ unknowns. The equations can be written in different notations, here are several examples that should be familiar to you: \n",
    "\n",
    "$$\\sum_{j}a_{ij}x_{j}=b_{i}\\qquad i=1,2,\\ldots,m$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\underbrace{\\left[\\begin{array}{cccc}\n",
    "a_{11} & a_{12} & \\cdots & a_{1n}\\\\\n",
    "a_{21} & a_{22} & \\cdots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
    "\\end{array}\\right]}_{A}\\underbrace{\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}}_{x}=\\underbrace{\\begin{bmatrix}b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{m}\n",
    "\\end{bmatrix}}_{b}\n",
    "$$\n",
    "\n",
    "or more succinctly \n",
    "\n",
    "$$ A\\cdot x=b$$\n",
    "\n",
    "where $A$ is an $m\\times n$ matrix of real coefficients, $b$ is an $m$ element vector of constants, and $x$ denotes the $n$ unknowns. No matter how the equations may be written, the task is to find values for $x_{1},x_{2},\\ldots,x_{n}$ that satisfying these equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can go wrong?\n",
    "\n",
    "Solutions are easy to find for simple problems. For example, you should be able to solve the following set of two equations in two unknowns.\n",
    "\n",
    "\\begin{align*}\n",
    "x_{1}+x_{2} & =4\\\\\n",
    "x_{1}-x_{2} & =2\n",
    "\\end{align*}\n",
    "\n",
    "Here are three additional sets of equations. What can you say about\n",
    "the solution to these examples?\n",
    "\n",
    "Case 1 --\n",
    "\n",
    "\\begin{align*}\n",
    "x_{1}+x_{2} & =4\\\\\n",
    "x_{1}-x_{2} & =2\\\\\n",
    "x_{1}+2x_{2} & =5\n",
    "\\end{align*}\n",
    "\n",
    "Case 2 --\n",
    "\n",
    "\\begin{align*}\n",
    "x_{1}+x_{2}+x_{3} & =4\\\\\n",
    "x_{1}-x_{2}-x_{3} & =2\n",
    "\\end{align*}\n",
    "\n",
    "Case 3 --\n",
    "\n",
    "\\begin{align*}\n",
    "x_{1}+x_{2} & =4\\\\\n",
    "x_{1}-x_{2} & =2\\\\\n",
    "x_{1}+2x_{2} & =5.001\n",
    "\\end{align*}\n",
    "\n",
    "What can go wrong when solving linear equations?\n",
    "\n",
    "### The problem is overspecified.\n",
    "\n",
    "There are more equations than unknowns. If the equations are consistent then there may still be a solution. Howover, the equations will generally be inconsistent and the best we can do is find a solution that approximately solves the equations. These problem arise in parameter fitting, estimation, and data mining problems where one attempts to fit large amounts of data using simple models.\n",
    "\n",
    "### The problem is underspecified.\n",
    "\n",
    "This occurs when $\\mbox{rank}(A)<n$, such as when $m<n$. There are not enough linearly independent equations to specify a unique solution. This occurs in control and decision problems where the extra degrees of freedom represent design choices. Additional criteria are required to winnow the family of possible solutions to those of engineering value.\n",
    "\n",
    "### The solution is sensitive to small changes in the parameters.\n",
    "\n",
    "As an example, consider\\cite{Tee1972a} \n",
    "\n",
    "$$A=\\left[\\begin{array}{ccc}\n",
    "11 & 10 & 14\\\\\n",
    "12 & 11 & -13\\\\\n",
    "14 & 13 & -66\n",
    "\\end{array}\\right]\\qquad b=\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "The determinant of $A$ is $\\det(A)=1$ so the matrix is full rank. Computing a solution to $Ax=b$ yields \n",
    "\n",
    "$$\n",
    "x=A\\backslash b=\\left[\\begin{array}{ccc}\n",
    "11 & 10 & 14\\\\\n",
    "12 & 11 & -13\\\\\n",
    "14 & 13 & -66\n",
    "\\end{array}\\right]\\backslash\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "-1\\\\\n",
    "0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Is this a solution you're willing to use for engineering work? Let's look at the impact of small changes in parameter values. Consider a 0.1\\% change in the values of $b$. Changing $b$ by a small amount results in a completely different solution with different signs for the $x_{1}$ and $x_{2}$.\n",
    "\n",
    "$$\n",
    "x=A\\backslash b=\\left[\\begin{array}{ccc}\n",
    "11 & 10 & 14\\\\\n",
    "12 & 11 & -13\\\\\n",
    "14 & 13 & -66\n",
    "\\end{array}\\right]\\backslash\\left[\\begin{array}{c}\n",
    "1.001\\\\\n",
    "0.999\\\\\n",
    "1.001\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "-0.683\\\\\n",
    "0.843\\\\\n",
    "0.006\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Changing $a_{22}$ by just 0.01\\% leads to even larger changes in the solution \n",
    "\n",
    "$$\n",
    "x=A\\backslash b=\\left[\\begin{array}{ccc}\n",
    "11 & 10 & 14\\\\\n",
    "12 & 11.001 & -13\\\\\n",
    "14 & 13 & -66\n",
    "\\end{array}\\right]\\backslash\\left[\\begin{array}{c}\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\n",
    "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
    "11.7949\\\\\n",
    "-12.8205\\\\\n",
    "-0.0385\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Problems list this example exhibiting extreme sensitivity to problem parameters are called _ill-conditioned_. Ill-conditioning in process control applications can result in loss of control and stability issues. \n",
    "\n",
    "\\marginnote{One of the issues in the development of control theory and applications\n",
    "has been understanding the role of parameter uncertainty in control\n",
    "system performance. The Grippen JAS 39A aircraft is a case where instability\n",
    "was attributed to a 'software glitch' with catastrophic results. ``Unfortunately,\n",
    "the first JAS 39A prototype, the \\textquotedbl{}39-1\\textquotedbl{},\n",
    "was lost on 2 February 1989 due to a software glitch in the flight-control\n",
    "system. The aircraft became unstable on landing ....''}\n",
    "\n",
    "The set of equations and unknowns is so large that computing a exact solution is prohibitively expensive.\n",
    "\n",
    "\n",
    "All of these issues commonly arise in real-world applications of linear\n",
    "algebra. Addressing them requires notions of approximation, sensitivity\n",
    "to computational error, and the management of error in numerical calculations.\n",
    "Familiar elements of linear algebra, such as determinant of a matrix,\n",
    "requiring exact arithmetic must be abandoned in favor of methods that\n",
    "take into account real-world issues of uncertainty and constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Norms\n",
    "\n",
    "A vector norm measures the size of a vector quantity. Later we will see that, by extension, a vector norm induces a measure for a matrix. \n",
    "\n",
    "Given an $n$-element vector $x$, the most familar measure is the Euclidean norm given by the scalar function of $x$\n",
    "\n",
    "$$\n",
    "\\|x\\|=\\sqrt{\\sum_{i=1}^{n}x_{i}^{2}}\n",
    "$$\n",
    "\n",
    "This is the measure of distance from the origin where $x$ denotes a point in space in 2 and 3 dimensional Euclidean geometry. \n",
    "\n",
    "For all vectors $x$ and $y$, and any scalar $\\alpha$, this norm satisfies the four properties: \n",
    "\n",
    "* $\\|x\\|\\geq0$ for all $x$.\n",
    "* $\\|x\\|=0$ if and only if $x=0$\n",
    "* $\\|x+y\\|\\leq\\|x\\|+\\|y\\|\\qquad$$\\qquad$\n",
    "* $\\|\\alpha x\\|=|\\alpha|\\,\\|x\\|$\n",
    "\n",
    "These properties are important because they provide the means to measure how close one vector is to another. For example, given two vectors $x$ and $y$, if $\\|x-y\\|=0$ then the second property tells us that $x=y$. Preperty 3 is the triangle inequality which is used in Euclidean geometry to prove that the shortest distance between two points is a straight line.\n",
    "\n",
    "Examples of vector norms:\n",
    "\n",
    "* $\\|x\\|_{1}=\\sum_{i=1}^{n}|x_{i}|$\n",
    "* $\\|x\\|_{2}=\\sqrt{\\sum_{i=1}^{n}x_{i}^{2}}=\\sqrt{x^{T}x}$\n",
    "* $\\|x\\|_{\\infty}=\\max_{i}|x_{i}|$\n",
    "* $\\|x\\|_{p}=\\left(\\sum_{i=1}^{n}|x_{i}|\\right)^{1/p}$\n",
    "\n",
    "Any scalar function of a vector which has these properties will serve\n",
    "as a norm. Some common examples are listed in the adjacent table.\n",
    "\n",
    "##### Exercise.\n",
    "\n",
    "Given the vector\n",
    "\n",
    "$$\n",
    "x=\\left[\\begin{array}{c}\n",
    "-3\\\\\n",
    "2\\\\\n",
    "1\\\\\n",
    "3\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "compute values for $\\|x\\|_{1}$, $\\|x\\|_{2}$, $\\|x\\|_{\\infty}$.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square, Full-Rank Systems\n",
    "\n",
    "Most students are familiar with the case when the number of equations\n",
    "is equal to the number of unknowns, that is when $m=n$. If the rank\n",
    "of $A$ is equal to $n$, then the equations are linearly independent\n",
    "and there exists a unique solution which may be represented as\n",
    "\\[\n",
    "x=A^{-1}b\n",
    "\\]\n",
    "where $A^{-1}$ denotes the matrix inverse. For an $n\\times n$ matrix\n",
    "the following conditions are equivalent:\n",
    "\\begin{itemize}\n",
    "\\item $A$ has an inverse $A^{-1}$ such that $A\\cdot A^{-1}=A^{-1}\\cdot A=I$\n",
    "\\item $A$ has rank $n$, i.e., $\\mbox{rank}(A)=n$.\n",
    "\\item $0$ is not an eigenvalue of $A$.\n",
    "\\end{itemize}\n",
    "There's an ugly secret about the matrix inverse. In practice there\n",
    "is usually no reason to ever actually compute $A^{-1}$. Most often\n",
    "it is a better idea to compute the solution directly using Gaussian\n",
    "elimination or more specialized algorithms. Solving $Ax=b$ without\n",
    "explicitly constructing the matrix inverse is usually at least $2\\times$\n",
    "to $3\\times$ faster, offer 1 to 2 digits more accuracy, and use less\n",
    "memory. As we will see below, even if one has to solve the same system\n",
    "of equations for different values of $b$, it is better to compute\n",
    "and store factorizations of $A$ then to compute and use the inverse\n",
    "$A^{-1}$. There are important exceptions such as applications in\n",
    "3D graphics and cryptography. These are exceptions that prove the\n",
    "rule. \n",
    "\n",
    "\\marginnote{If $A$ is full rank then both $x=A\\backslash b$ and $x=A^{-1}b$\n",
    "compute a unique solution. But $x=A\\backslash b$ does it $2\\times$\n",
    "to $3\\times$ faster, with 1-2 digits more accuracy, and uses less\n",
    "memory.}\n",
    "\n",
    "When reading applied linear algebra one should normally interpret\n",
    "$A^{-1}b$ as the solution to $Ax=b$ instead of the computation of\n",
    "a matrix inverse followed by matrix/vector multiplication. We make\n",
    "this distinction clear with the Matlab convention\n",
    "\\[\n",
    "x=A\\backslash b\n",
    "\\]\n",
    "to denote the desired implied calculation. As an example, the formula\n",
    "for $\\tilde{B}$ in the conversion of a continuous-time linear system\n",
    "to a discrete-time system could be written as either \n",
    "\\begin{align*}\n",
    "\\tilde{B} & =\\left(e^{A\\Delta t}-I\\right)A^{-1}B\\\\\n",
    " & =\\left(e^{A\\Delta t}-I\\right)(A\\backslash B)\n",
    "\\end{align*}\n",
    "$\\left(A\\backslash B\\right)$ more accurately conveys the actual computational\n",
    "procedure for $\\tilde{B}$. Note the significance of the parentheses\n",
    "surrounding $A\\backslash B$ in this expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-determined Systems: Least Squares\n",
    "\n",
    "Norms help us solve linear equations. We first consider the case of\n",
    "an $m\\times n$ system of equations where $m>n$. With more equations\n",
    "than unknowns, in general we cannot expect to find an exact solution.\n",
    "Instead, we define an $m$-element error vector $e$\n",
    "\\[\n",
    "e=Ax-b\n",
    "\\]\n",
    "By solution, we mean a vector $x_{LS}$ which minimizes $\\|e\\|_{2}$\n",
    "where the Euclidean norm measures the size of the error vector. That\n",
    "is, we wish to minimize\n",
    "\\[\n",
    "\\min_{x}\\|e\\|_{2}^{2}=\\min_{x}\\|Ax-b\\|_{2}^{2}\n",
    "\\]\n",
    "the vector $x_{LS}$ is that value of $x$ that minimizes the sum\n",
    "of squares of $e$. Working this out\n",
    "\\begin{align*}\n",
    "\\|Ax-b\\|_{2}^{2} & =\\left(Ax-b\\right)^{T}\\left(Ax-b\\right)\\\\\n",
    " & =x^{T}A^{T}Ax-2x^{T}A^{T}b+b^{T}b\n",
    "\\end{align*}\n",
    "Taking the partial derivative of the right hand side with respect\n",
    "to $ $$x$ and setting to zero gives us an equation for $x_{LS}$\n",
    "\\[\n",
    "A^{T}Ax_{LS}-A^{T}b=0\n",
    "\\]\n",
    "The product $A^{T}A$ is $m\\times m$. If full rank, then a unique\n",
    "solution exists which can be computed \n",
    "\\begin{align*}\n",
    "x_{LS} & =\\underbrace{\\left(A^{T}A\\right)^{-1}A^{T}}_{A^{+}}b\\\\\n",
    " & =\\underbrace{\\left(A^{T}A\\right)\\backslash A^{T}}_{A^{\\dagger}}b\n",
    "\\end{align*}\n",
    "where $A^{+}$ is called the generalized inverse of$A$. This is a\n",
    "useful result for many engineering and data mining applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\subsection*{Example: Least Squares Fitting }\n",
    "\n",
    "Suppose are given a model for diffusivity $D_{AB}$ as a function\n",
    "of absolute temperature $T$\n",
    "\\[\n",
    "D_{AB}=CT^{\\alpha}\n",
    "\\]\n",
    "and a set of laboratory data\n",
    "\n",
    "\\begin{center}\n",
    "\\begin{tabular}{|c|c|}\n",
    "\\hline \n",
    "$T$ {[}$K${]} & $D_{AB}$ {[}$cm^{2}/sec]$\\tabularnewline\n",
    "\\hline \n",
    "\\hline \n",
    "275 & 0.201\\tabularnewline\n",
    "\\hline \n",
    "283 & 0.230\\tabularnewline\n",
    "\\hline \n",
    "303 & \\tabularnewline\n",
    "\\hline \n",
    "340 & \\tabularnewline\n",
    "\\hline \n",
    "353 & \\tabularnewline\n",
    "\\hline \n",
    "370 & \\tabularnewline\n",
    "\\hline \n",
    "\\end{tabular}\n",
    "\\par\\end{center}\n",
    "\n",
    "Taking logarithms, the model can be rewritten as\n",
    "\\[\n",
    "\\log D_{AB}=\\log C+\\alpha\\log T\n",
    "\\]\n",
    "Then for each measurement we have an equation\n",
    "\\[\n",
    "\\log D_{AB,i}=\\log C+\\alpha\\log T_{i}\\qquad i=1,2,\\ldots,6\n",
    "\\]\n",
    "which forms a set of six linear equations in the the two unknowns,\n",
    "$\\log C$ and $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underdetermined Systems: Minimum Norm\n",
    "\n",
    "If $ $$m<n$ then the system of equations $Ax=b$ is underdetermined.\n",
    "There many possible values of $x$ that satisfy the $m$ equality\n",
    "specifications. \n",
    "\\[\n",
    "\\min_{x}\\|x\\|_{2}^{2}\n",
    "\\]\n",
    "subject to \n",
    "\\[\n",
    "Ax=b\n",
    "\\]\n",
    "Following standard procedures for equality constrained optimization\n",
    "problems, we form the Lagrangian\n",
    "\\[\n",
    "{\\cal L}=\\frac{1}{2}x^{T}x+\\lambda^{T}(Ax-b)\n",
    "\\]\n",
    "and minimize with respect to $x$ and the Lagrange multipliers $\\lambda$.\n",
    "The necessary conditions for a Solving we find\n",
    "\\begin{align*}\n",
    "x_{LS} & =\\underbrace{A^{T}\\left(AA^{T}\\right)^{-1}}_{A^{+}}b\\\\\n",
    " & =\\underbrace{\\left(A^{T}/\\left(AA^{T}\\right)\\right)}_{A^{\\dagger}}b\n",
    "\\end{align*}\n",
    "which is well-defined provided the $m\\times m$ matrix $ $$AA^{T}$\n",
    "is full rank. This is the mi\n",
    "\n",
    "\n",
    "\\subsection{Ill-Conditioned and Rank Defective}\n",
    "\n",
    "Singular Value Decomposition and Wiener Filtering Tikinov regularization\n",
    "can be used for cases where the matrix $A$ is ill-conditioned. \n",
    "\n",
    "\n",
    "\\section{Summary}\n",
    "\\begin{fullwidth}\n",
    "\\begin{tabular}{lccccl>{\\raggedright}p{1.25in}}\n",
    "\\toprule\n",
    "{\\small{}Case} & {\\small{}Dim.} & {\\small{}Rank} & {\\small{}Condition} & {\\small{}Symbolic Solution} & {\\small{}Matlab Solution} & {\\small{}Comments}\\tabularnewline\n",
    "\\midrule\n",
    "{\\small{}Square, full rank} & {\\small{}$m=n$} & {\\small{}$n$} & {\\small{}$<10^{6}$} & {\\small{}$x=A^{-1}b$} & \\texttt{\\small{}x=A\\textbackslash{}b;} & {\\small{}Preferred}\\tabularnewline\n",
    " &  &  &  &  & \\texttt{\\small{}x=inv(A){*}b;} & {\\small{}Slower, less accurate}\\tabularnewline\n",
    "\\hline \n",
    "{\\small{}Overdetermined} & {\\small{}$m>n$} & {\\small{}$n$} & {\\small{}$<10^{6}$} & {\\small{}$x=(A^{T}A)^{-1}A^{T}b$} & \\texttt{\\small{}x=A\\textbackslash{}b;} & {\\small{}Least-Squares}\\tabularnewline\n",
    " &  &  &  &  & \\texttt{\\small{}x=(A'{*}A)\\textbackslash{}(A'{*}b);} & {\\small{}Least-Squares}\\tabularnewline\n",
    "\\midrule \n",
    "{\\small{}Underdetermined} & {\\small{}$m<n$} & {\\small{}$m$} & {\\small{}$<10^{6}$} & {\\small{}$x=A^{T}(AA^{T})^{-1}b$} & \\texttt{\\small{}x=A'{*}((A{*}A')\\textbackslash{}b)} & {\\small{}Minimum $\\|x\\|_{2}$}\\tabularnewline\n",
    " &  &  &  &  & \\texttt{\\small{}x=A\\textbackslash{}b;} & {\\small{}Minimum non-zeros}\\tabularnewline\n",
    "\\midrule \n",
    "{\\small{}Ill-conditioned} &  & $r$ &  & {\\small{}$x=VS^{\\dagger}U'$} &  & {\\small{}Singular Value Decomposition}\\tabularnewline\n",
    "\\midrule \n",
    "{\\small{}Large, Sparse} & {\\small{}$n>10^{3}$} &  &  &  &  & {\\small{}Sparse Matrices}\\tabularnewline\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{fullwidth}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Norms\n",
    "\n",
    "An $m\\times n$ matrix $A$ maps an $n$-element to an $m$-element\n",
    "result. For a particular $x$ we can measure the 'gain' with the ratio\n",
    "$\\frac{\\|Ax\\|_{p}}{\\|x\\|_{p}}$. Looking for the largest possible\n",
    "value of that ratio gives us expression\n",
    "\\[\n",
    "\\|A\\|_{p}=\\sup_{x}\\frac{\\|Ax\\|_{p}}{\\|x\\|_{p}}\n",
    "\\]\n",
    "which is the matrix norm induced by the vector norm $\\|\\cdot\\|_{p}$.\n",
    "\\marginnote{Properties of a matrix norm. For any two $m\\times n$ matrices $A$\n",
    "and $B$, and any scalar $\\alpha$,\n",
    "\\begin{enumerate}\n",
    "\\item $\\|A\\|\\geq0$ for all $A$.\n",
    "\\item $\\|A\\|=0$ if and only if $A=0$\n",
    "\\item $\\|A+B\\|\\leq\\|A\\|+\\|B\\|\\qquad$$\\qquad$\n",
    "\\item $\\|\\alpha A\\|=|\\alpha|\\,\\|A\\|$\\end{enumerate}\n",
    "} For any pair of $m\\times n$ matrix $A$ and $B$, and any scalar\n",
    "$\\alpha$, the matrix norm satisfies four important properties:\n",
    "\\begin{enumerate}\n",
    "\\item $\\|A\\|\\geq0$ for all $A$.\n",
    "\\item $\\|A\\|=0$ if and only if $A=0$\n",
    "\\item $\\|A+B\\|\\leq\\|A\\|+\\|B\\|\\qquad$$\\qquad$\n",
    "\\item $\\|\\alpha A\\|=|\\alpha|\\,\\|A\\|$\n",
    "\\end{enumerate}\n",
    "These are the same properties outlined above for a vector norm. What's\n",
    "happened here is that we've used the vector norm to induce a norm\n",
    "for a matrix. Explicit formulae can be found for several examples\n",
    "of matrix norms\n",
    "\\begin{itemize}\n",
    "\\item $\\|A\\|_{1}=\\max_{1\\leq j\\leq n}\\sum_{i=1}^{m}|a_{ij}|$ i.e., the\n",
    "maximum absolute row sum.\n",
    "\\item $\\|A\\|_{2}=\\max_{i}\\sqrt{\\lambda_{i}\\left(A^{T}A\\right)}$ where $\\lambda_{i}(A^{T}A)$\n",
    "denotes the $i^{th}$ eigenvalue of $A^{T}A$\n",
    "\\item $\\|A\\|_{\\infty}=\\max_{1\\leq i\\leq m}\\sum_{j=1}^{n}|a_{ij}|$ i.e.,\n",
    "the maximum absolute column sum\n",
    "\\item $\\|A\\|_{F}=\\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}a_{ij}^{2}}$ Frobenius\n",
    "Norm\n",
    "\\end{itemize}\n",
    "The result for the matrix norm $\\|A\\|_{2}$ is especially important\n",
    "in applications of linear algebra. \n",
    "\\begin{align*}\n",
    "\\|A\\|_{2}^{2} & =\\sup_{x}\\frac{\\|Ax\\|_{2}^{2}}{\\|x\\|_{2}^{2}}=\\sup_{x}\\frac{x^{T}A^{T}Ax}{x^{T}x}\n",
    "\\end{align*}\n",
    "Without going through an extended derivation, the value of $x$ which\n",
    "maximizes this ratio solves an eigenvalue problem written as\n",
    "\\[\n",
    "\\left(A^{T}A\\right)u_{i}=\\sigma_{i}^{2}u_{i}\n",
    "\\]\n",
    "so that\n",
    "\\[\n",
    "\\|A\\|_{2}=\\max_{i}\\sigma_{i}\n",
    "\\]\n",
    "The non-zero values $\\sigma_{1},\\sigma_{2},.\\ldots,\\sigma_{r}$ which\n",
    "satisfy this equation are the singular values of $A$. \n",
    "\n",
    "where $\\sigma^{2}$ is the s computed as the square root of the maximum\n",
    "eigenvalue of $A^{T}A$. Recall that the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\section*{Exercises}\n",
    "\\begin{enumerate}\n",
    "\\item You are given a regression problem in which you need to fit the reaction\n",
    "rate data shown in the accompanying table to a first-order model\n",
    "\\[\n",
    "R=kc_{A}\n",
    "\\]\n",
    "where $k$ is rate constant that needs to be determined. \n",
    "\\begin{margintable}\n",
    "\n",
    "\n",
    "\\protect\\caption{Data for regression of a first-order reaction rate model.}\n",
    "\n",
    "\n",
    "\\begin{centering}\n",
    "\\bigskip{}\n",
    "\\begin{tabular}{r@{\\extracolsep{0pt}.}l|r@{\\extracolsep{0pt}.}l}\n",
    "\\multicolumn{2}{c|}{$c_{A}$ {[}mol/l{]}} & \\multicolumn{2}{c}{$R$ {[}mol/l/hr{]}}\\tabularnewline\n",
    "\\hline \n",
    "0&0 & 0&0\\tabularnewline\n",
    "0&1 & 1&2\\tabularnewline\n",
    "0&2 & 2&0\\tabularnewline\n",
    "0&3 & 3&5\\tabularnewline\n",
    "0&4 & 5&0\\tabularnewline\n",
    "0&5 & 6&2\\tabularnewline\n",
    "0&6 & 7&0\\tabularnewline\n",
    "\\end{tabular}\n",
    "\\par\\end{centering}\n",
    "\n",
    "\\end{margintable}\n",
    "\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item Set up the regression problem as a set of over-determined linear equations\n",
    "\\[\n",
    "Ax=b\n",
    "\\]\n",
    "Show the contents of the matrix $A$ and vector $b$.\n",
    "\\item The least-squares solution is given by $x=\\left(A^{T}A\\right)^{-1}A^{T}b$.\n",
    "What are the dimensions of $A^{T}A$ and $A^{T}b$? Compute the solution\n",
    "by hand.\n",
    "\\end{enumerate}\n",
    "\\end{enumerate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
