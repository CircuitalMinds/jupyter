{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://arxiv.org/rss/cs.CV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = feedparser.parse(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bozo': 0,\n",
      " 'encoding': 'us-ascii',\n",
      " 'entries': [...],\n",
      " 'etag': '\"Fri, 26 Jul 2019 00:30:00 GMT\", \"1564101000\"',\n",
      " 'feed': {...},\n",
      " 'headers': {...},\n",
      " 'href': 'http://export.arxiv.org/rss/cs.CV',\n",
      " 'namespaces': {...},\n",
      " 'status': 301,\n",
      " 'updated': 'Fri, 26 Jul 2019 00:30:00 GMT',\n",
      " 'updated_parsed': time.struct_time(tm_year=2019, tm_mon=7, tm_mday=26, tm_hour=0, tm_min=30, tm_sec=0, tm_wday=4, tm_yday=207, tm_isdst=0),\n",
      " 'version': 'rss10'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(d, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(d['entries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "print(len(d['entries']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'feedparser.FeedParserDict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(d['entries'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': '<a href=\"http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1\">Vinod Kumar Kurmi</a>, '\n",
      "           '<a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_V/0/1/0/all/0/1\">Vipul Bajaj</a>, <a '\n",
      "           'href=\"http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1\">Venkatesh K '\n",
      "           'Subramanian</a>, <a '\n",
      "           'href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay P '\n",
      "           'Namboodiri</a>',\n",
      " 'author_detail': {'name': '<a href=\"http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1\">Vinod '\n",
      "                           'Kumar Kurmi</a>, <a '\n",
      "                           'href=\"http://arxiv.org/find/cs/1/au:+Bajaj_V/0/1/0/all/0/1\">Vipul '\n",
      "                           'Bajaj</a>, <a '\n",
      "                           'href=\"http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1\">Venkatesh '\n",
      "                           'K Subramanian</a>, <a '\n",
      "                           'href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay '\n",
      "                           'P Namboodiri</a>'},\n",
      " 'authors': [{'name': '<a href=\"http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1\">Vinod Kumar '\n",
      "                      'Kurmi</a>, <a '\n",
      "                      'href=\"http://arxiv.org/find/cs/1/au:+Bajaj_V/0/1/0/all/0/1\">Vipul '\n",
      "                      'Bajaj</a>, <a '\n",
      "                      'href=\"http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1\">Venkatesh '\n",
      "                      'K Subramanian</a>, <a '\n",
      "                      'href=\"http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1\">Vinay P '\n",
      "                      'Namboodiri</a>'}],\n",
      " 'id': 'http://arxiv.org/abs/1907.10628',\n",
      " 'link': 'http://arxiv.org/abs/1907.10628',\n",
      " 'links': [{'href': 'http://arxiv.org/abs/1907.10628', 'rel': 'alternate', 'type': 'text/html'}],\n",
      " 'summary': '<p>Domain adaptation is essential to enable wide usage of deep learning based\\n'\n",
      "            'networks trained using large labeled datasets. Adversarial learning based\\n'\n",
      "            'techniques have shown their utility towards solving this problem using a\\n'\n",
      "            'discriminator that ensures source and target distributions are close. However,\\n'\n",
      "            'here we suggest that rather than using a point estimate, it would be useful if\\n'\n",
      "            'a distribution based discriminator could be used to bridge this gap. This could\\n'\n",
      "            'be achieved using multiple classifiers or using traditional ensemble methods.\\n'\n",
      "            'In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator\\n'\n",
      "            'could suffice to obtain the distribution based discriminator. Specifically, we\\n'\n",
      "            'propose a curriculum based dropout discriminator that gradually increases the\\n'\n",
      "            'variance of the sample based distribution and the corresponding reverse\\n'\n",
      "            'gradients are used to align the source and target feature representations. The\\n'\n",
      "            'detailed results and thorough ablation analysis show that our model outperforms\\n'\n",
      "            'state-of-the-art results.\\n'\n",
      "            '</p>',\n",
      " 'summary_detail': {'base': 'http://export.arxiv.org/rss/cs.CV',\n",
      "                    'language': None,\n",
      "                    'type': 'text/html',\n",
      "                    'value': '<p>Domain adaptation is essential to enable wide usage of deep '\n",
      "                             'learning based\\n'\n",
      "                             'networks trained using large labeled datasets. Adversarial learning '\n",
      "                             'based\\n'\n",
      "                             'techniques have shown their utility towards solving this problem '\n",
      "                             'using a\\n'\n",
      "                             'discriminator that ensures source and target distributions are '\n",
      "                             'close. However,\\n'\n",
      "                             'here we suggest that rather than using a point estimate, it would be '\n",
      "                             'useful if\\n'\n",
      "                             'a distribution based discriminator could be used to bridge this gap. '\n",
      "                             'This could\\n'\n",
      "                             'be achieved using multiple classifiers or using traditional ensemble '\n",
      "                             'methods.\\n'\n",
      "                             'In contrast, we suggest that a Monte Carlo dropout based ensemble '\n",
      "                             'discriminator\\n'\n",
      "                             'could suffice to obtain the distribution based discriminator. '\n",
      "                             'Specifically, we\\n'\n",
      "                             'propose a curriculum based dropout discriminator that gradually '\n",
      "                             'increases the\\n'\n",
      "                             'variance of the sample based distribution and the corresponding '\n",
      "                             'reverse\\n'\n",
      "                             'gradients are used to align the source and target feature '\n",
      "                             'representations. The\\n'\n",
      "                             'detailed results and thorough ablation analysis show that our model '\n",
      "                             'outperforms\\n'\n",
      "                             'state-of-the-art results.\\n'\n",
      "                             '</p>'},\n",
      " 'title': 'Curriculum based Dropout Discriminator for Domain Adaptation. (arXiv:1907.10628v1 '\n",
      "          '[cs.LG])',\n",
      " 'title_detail': {'base': 'http://export.arxiv.org/rss/cs.CV',\n",
      "                  'language': None,\n",
      "                  'type': 'text/plain',\n",
      "                  'value': 'Curriculum based Dropout Discriminator for Domain Adaptation. '\n",
      "                           '(arXiv:1907.10628v1 [cs.LG])'}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(d['entries'][0], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/abs/1907.10628\n"
     ]
    }
   ],
   "source": [
    "print(d['entries'][0]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curriculum based Dropout Discriminator for Domain Adaptation. (arXiv:1907.10628v1 [cs.LG])\n"
     ]
    }
   ],
   "source": [
    "print(d['entries'][0]['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
